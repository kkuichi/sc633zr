{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea44c92febb688f7",
   "metadata": {},
   "source": [
    "## Importovanie knižníc"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-05-18T12:06:01.507426Z",
     "start_time": "2025-05-18T12:05:59.705856Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from hiclass.metrics import precision as h_precision, recall as h_recall, f1 as h_f1\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "a719661fbdc91aed",
   "metadata": {},
   "source": [
    "## Predspracovanie dát\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "eeafcfe2ebfbb2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:06:12.566502Z",
     "start_time": "2025-05-18T12:06:12.558915Z"
    }
   },
   "source": [
    "def preprocess_data(file_path):\n",
    "    relevant_features = [\n",
    "        'Vek',\n",
    "        'Pohlavie',\n",
    "        'Fajčenie',\n",
    "        'Alkohol',\n",
    "        'Hypertenzia',\n",
    "        'Diabetes mellitus',\n",
    "        'Kardiovaskulárne ochorenia',\n",
    "        'Chronické respiračné ochorenia',\n",
    "        'Renálne ochorenia',\n",
    "        'Pečeňové ochorenia',\n",
    "        'Onkologické ochorenia',\n",
    "        'Imunosupresia',\n",
    "        'Závažnosť priebehu ochorenia'\n",
    "    ]\n",
    "\n",
    "    data = pd.read_excel(file_path, usecols=relevant_features)\n",
    "\n",
    "    # Odstránenie záznamov s chýbajúcou cieľovou premennou\n",
    "    data=data.dropna(subset=['Závažnosť priebehu ochorenia'])\n",
    "\n",
    "    # Konverzia kategórie \"Pohlavie\" na binárnu formu (one-hot encoding)\n",
    "    data = pd.get_dummies(data, columns=['Pohlavie'], drop_first=True)\n",
    "\n",
    "     # Vytvorenie nových cieľových premenných pre modelovanie úmrtnosti a závažnosti\n",
    "    data[\"Mortality\"] = data[\"Závažnosť priebehu ochorenia\"].apply(lambda x: 1 if x == 3 else 0)\n",
    "    data[\"Severity\"] = data[\"Závažnosť priebehu ochorenia\"].replace({3: np.nan, 1: 0, 2: 1})\n",
    "\n",
    "    X = data.drop(columns=['Závažnosť priebehu ochorenia', 'Mortality', 'Severity'])\n",
    "    y_mortality = data['Mortality']\n",
    "    y_severity = data['Severity']\n",
    "    y_true = data['Závažnosť priebehu ochorenia']\n",
    "\n",
    "    return X, y_mortality, y_severity, y_true\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "75b813eabeca8981",
   "metadata": {},
   "source": [
    "## Trénovanie modelu Random Forest s využitím pipeline a grid search optimalizácie"
   ]
  },
  {
   "cell_type": "code",
   "id": "b74a691a2a0f5663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:06:21.659121Z",
     "start_time": "2025-05-18T12:06:21.651023Z"
    }
   },
   "source": [
    "\n",
    "def train_random_forest(X, y, preprocessor, scoring='f1_weighted', random_state=42):\n",
    "\n",
    "\n",
    "    pipeline = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        # ('resampler', SMOTE(random_state=random_state)), # V prípade potreby odstráňte komentáre ( vykazuje horšie výsledky)\n",
    "        ('classifier', RandomForestClassifier(random_state=random_state, class_weight='balanced'))\n",
    "    ])\n",
    "\n",
    "    # Nastavenie grid search pre hľadanie najlepších hyperparametrov modelu\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [100, 150, 200],\n",
    "        'classifier__max_depth': [None, 5, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],\n",
    "        'classifier__max_features': ['sqrt', 'log2'],\n",
    "        'classifier__bootstrap': [True, False],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "   # Spustenie grid search s 5-násobnou krížovou validáciou\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring=scoring,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    print(\"Best parameters:\", grid.best_params_)\n",
    "    return grid.best_estimator_"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "23a87633f1c2e1f2",
   "metadata": {},
   "source": [
    "## Vyhodnotenie predikcií modelu pomocou hierarchických metrík (knižnica hiclass)."
   ]
  },
  {
   "cell_type": "code",
   "id": "34829a60a2830ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:06:24.165429Z",
     "start_time": "2025-05-18T12:06:24.158463Z"
    }
   },
   "source": [
    "def evaluate_predictions(y_true, y_pred):\n",
    "\n",
    "    # Pomocná funkcia na konverziu tried do formátu vhodného pre hierarchické metriky\n",
    "    def convert_to_hiclass_format(label):\n",
    "        if label == 1:\n",
    "            return [\"0\", \"2\"]\n",
    "        elif label == 2:\n",
    "            return [\"0\", \"3\"]\n",
    "        elif label == 3:\n",
    "            return [\"1\"]\n",
    "\n",
    "    y_true_h = [convert_to_hiclass_format(label) for label in y_true]\n",
    "    y_pred_h = [convert_to_hiclass_format(label) for label in y_pred]\n",
    "\n",
    "    print(\"\\n=== Hierarchical Metrics ===\")\n",
    "    print(f\"H-Precision: {h_precision(y_true_h, y_pred_h):.4f}\")\n",
    "    print(f\"H-Recall:    {h_recall(y_true_h, y_pred_h):.4f}\")\n",
    "    print(f\"H-F1:        {h_f1(y_true_h, y_pred_h):.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "b1a1acf715b118a3",
   "metadata": {},
   "source": [
    "## V tejto časti prebieha hlavná príprava, trénovanie  a hodnotenie hierarchického modelu.\n",
    "> #### Model je dvojúrovňový - najprv sa predpovedá pravdepodobnosť úmrtia (mortality), a ak pacient nebol predikovaný ako zomrel, pokračuje sa druhým modelom (severity), ktorý určuje závažnosť ochorenia u preživších."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa499f56ab811638",
   "metadata": {},
   "source": [
    "### `Prvá vlna pandémie`"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b750eaf6292739f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:14:27.054887Z",
     "start_time": "2025-05-18T12:06:36.647563Z"
    }
   },
   "source": [
    "X, y_mortality, y_severity, y_true = preprocess_data('../data/1vlna.xlsx')\n",
    "feature_names = X.columns\n",
    "\n",
    "# Rozdelenie dát na trénovaciu a testovaciu množinu so stratifikáciou podľa cieľovej premennej úmrtnosti (pretože dáta sú nevyvážené).\n",
    "X_train, X_test, y_train_mort, y_test_mort = train_test_split(\n",
    "    X, y_mortality, test_size=0.3, random_state=42, stratify=y_mortality\n",
    ")\n",
    "\n",
    "# Definícia predspracovania - normalizuje sa len vek, ostatné premenné zostávajú nezmenené\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), ['Vek']),\n",
    "    ('passthrough', 'passthrough', X.columns.difference(['Vek']))\n",
    "])\n",
    "\n",
    "# Trénovanie modelu pre predikciu úmrtnosti\n",
    "mort_pipeline = train_random_forest(X_train, y_train_mort, preprocessor)\n",
    "\n",
    "# Získanie predpovedí Out-of-Fold (OOF) pre trénovacie dáta pri použití modelu úmrtnosti\n",
    "oof_predictions = cross_val_predict(\n",
    "    mort_pipeline, X_train, y_train_mort, cv=5, method='predict'\n",
    ")\n",
    "\n",
    "# Tento blok kódu vykonáva filtrovanie trénovacích dát, pričom vyberáme len tie prípady, ktoré model úmrtnosti\n",
    "# (mortality) predpovedal ako preživšie (0), a zároveň sa u týchto pacientov zaznamenáva úroveň závažnosti v\n",
    "# skutočných údajoch (to znamená, že skutočne prežili a mali inú úroveň závažnosti ako smrť).\n",
    "# Tieto dáta slúžia ako vstup pre druhý model – klasifikátor závažnosti.\n",
    "\n",
    "survivor_mask_train_pred_oof = (oof_predictions == 0)\n",
    "y_train_severity_mask = y_severity.loc[X_train.index].notna()\n",
    "relevant_mask_train = survivor_mask_train_pred_oof & y_train_severity_mask\n",
    "\n",
    "X_train_severity = X_train[relevant_mask_train]\n",
    "y_train_severity = y_severity.loc[X_train.index][relevant_mask_train]\n",
    "\n",
    "# Trénovanie modelu pre predikciu závažnosti na filtrovaných trénovacích dátach\n",
    "severity_pipeline = train_random_forest(X_train_severity, y_train_severity, preprocessor)\n",
    "\n",
    "# Predikcia umrtnosti (mortality) na testovacej množine\n",
    "y_pred_mortality_test = mort_pipeline.predict(X_test)\n",
    "survivor_mask_test = (y_pred_mortality_test == 0)\n",
    "\n",
    "# Príprava testovacích dát pre druhý model – len tí, ktorí boli predikovaní ako preživší.\n",
    "X_test_severity = X_test[survivor_mask_test]\n",
    "y_pred_severity = np.full(len(X_test), np.nan)\n",
    "\n",
    "\n",
    "# Ak existujú pacienti predikovaní ako preživší, aplikuje sa druhý model a zvýši sa predikovaná hodnota o 1,\n",
    "# aby sa hodnoty mapovali späť na pôvodné označenie tried (1 alebo 2).\n",
    "if not X_test_severity.empty:\n",
    "    y_pred_severity_survivors = severity_pipeline.predict(X_test_severity)\n",
    "    y_pred_severity[survivor_mask_test] = y_pred_severity_survivors + 1\n",
    "\n",
    "# Finalizácia predikcie:\n",
    "# - pacienti predikovaní ako zomrelí (1. model) dostanú hodnotu 3\n",
    "# - preživší dostanú predikovanú hodnotu závažnosti (1 alebo 2)\n",
    "final_pred = np.full(len(X_test), 3)\n",
    "final_pred[survivor_mask_test] = y_pred_severity[survivor_mask_test]\n",
    "final_pred = np.nan_to_num(final_pred, nan=3).astype(int)\n",
    "\n",
    "# Skutočné hodnoty pre testovaciu množinu\n",
    "y_true_final = y_true.loc[X_test.index]\n",
    "\n",
    "# Vyhodnotenie celkového výkonu hierarchického modelu\n",
    "evaluate_predictions(y_true_final, pd.Series(final_pred, index=X_test.index))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'entropy', 'classifier__max_depth': None, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'entropy', 'classifier__max_depth': None, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "\n",
      "=== Hierarchical Metrics ===\n",
      "H-Precision: 0.7461\n",
      "H-Recall:    0.7437\n",
      "H-F1:        0.7449\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "d8eb937e3556c7a0",
   "metadata": {},
   "source": [
    "> #### Úplne rovnaká štruktúra kódu je definovaná pre druhú, tretiu a štvrtú vlnu pandémie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa883491437ae7e",
   "metadata": {},
   "source": [
    "### `Druhá vlna pandémie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be2b6346a74be8a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:49:43.969039Z",
     "start_time": "2025-05-07T13:41:16.634334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 150}\n",
      "\n",
      "=== Hierarchical Metrics ===\n",
      "H-Precision: 0.7411\n",
      "H-Recall:    0.7651\n",
      "H-F1:        0.7529\n"
     ]
    }
   ],
   "source": [
    "X, y_mortality, y_severity, y_true = preprocess_data('../data/2vlna.xlsx')\n",
    "feature_names = X.columns\n",
    "\n",
    "X_train, X_test, y_train_mort, y_test_mort = train_test_split(\n",
    "    X, y_mortality, test_size=0.3, random_state=42, stratify=y_mortality\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), ['Vek']),\n",
    "    ('passthrough', 'passthrough', X.columns.difference(['Vek']))\n",
    "])\n",
    "\n",
    "mort_pipeline = train_random_forest(X_train, y_train_mort, preprocessor)\n",
    "\n",
    "oof_predictions = cross_val_predict(\n",
    "    mort_pipeline, X_train, y_train_mort, cv=5, method='predict'\n",
    ")\n",
    "survivor_mask_train_pred_oof = (oof_predictions == 0)\n",
    "\n",
    "\n",
    "y_train_severity_not_na_mask = y_severity.loc[X_train.index].notna()\n",
    "relevant_mask_train = survivor_mask_train_pred_oof & y_train_severity_not_na_mask\n",
    "X_train_severity = X_train[relevant_mask_train]\n",
    "y_train_severity = y_severity.loc[X_train.index][relevant_mask_train]\n",
    "\n",
    "\n",
    "severity_pipeline = train_random_forest(X_train_severity, y_train_severity, preprocessor)\n",
    "\n",
    "y_pred_mortality_test = mort_pipeline.predict(X_test)\n",
    "survivor_mask_test = (y_pred_mortality_test == 0)\n",
    "\n",
    "X_test_severity = X_test[survivor_mask_test]\n",
    "y_pred_severity = np.full(len(X_test), np.nan)\n",
    "\n",
    "if not X_test_severity.empty:\n",
    "    y_pred_severity_survivors = severity_pipeline.predict(X_test_severity)\n",
    "    y_pred_severity[survivor_mask_test] = y_pred_severity_survivors + 1\n",
    "\n",
    "final_pred = np.full(len(X_test), 3)\n",
    "final_pred[survivor_mask_test] = y_pred_severity[survivor_mask_test]\n",
    "final_pred = np.nan_to_num(final_pred, nan=3).astype(int)\n",
    "\n",
    "\n",
    "y_true_final = y_true.loc[X_test.index]\n",
    "evaluate_predictions(y_true_final, pd.Series(final_pred, index=X_test.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c08da39a225c44",
   "metadata": {},
   "source": [
    "### `Tretia vlna pandémie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea96b880ba3bf38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:59:14.268656Z",
     "start_time": "2025-05-07T13:51:08.598674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 150}\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "\n",
      "=== Hierarchical Metrics ===\n",
      "H-Precision: 0.7500\n",
      "H-Recall:    0.7154\n",
      "H-F1:        0.7323\n"
     ]
    }
   ],
   "source": [
    "X, y_mortality, y_severity, y_true = preprocess_data('../data/3vlna.xlsx')\n",
    "feature_names = X.columns\n",
    "\n",
    "X_train, X_test, y_train_mort, y_test_mort = train_test_split(\n",
    "    X, y_mortality, test_size=0.3, random_state=42, stratify=y_mortality\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), ['Vek']),\n",
    "    ('passthrough', 'passthrough', X.columns.difference(['Vek']))\n",
    "])\n",
    "\n",
    "mort_pipeline = train_random_forest(X_train, y_train_mort, preprocessor)\n",
    "\n",
    "oof_predictions = cross_val_predict(\n",
    "    mort_pipeline, X_train, y_train_mort, cv=5, method='predict'\n",
    ")\n",
    "survivor_mask_train_pred_oof = (oof_predictions == 0)\n",
    "\n",
    "\n",
    "y_train_severity_not_na_mask = y_severity.loc[X_train.index].notna()\n",
    "relevant_mask_train = survivor_mask_train_pred_oof & y_train_severity_not_na_mask\n",
    "X_train_severity = X_train[relevant_mask_train]\n",
    "y_train_severity = y_severity.loc[X_train.index][relevant_mask_train]\n",
    "\n",
    "\n",
    "severity_pipeline = train_random_forest(X_train_severity, y_train_severity, preprocessor)\n",
    "\n",
    "y_pred_mortality_test = mort_pipeline.predict(X_test)\n",
    "survivor_mask_test = (y_pred_mortality_test == 0)\n",
    "\n",
    "X_test_severity = X_test[survivor_mask_test]\n",
    "y_pred_severity = np.full(len(X_test), np.nan)\n",
    "\n",
    "if not X_test_severity.empty:\n",
    "    y_pred_severity_survivors = severity_pipeline.predict(X_test_severity)\n",
    "    y_pred_severity[survivor_mask_test] = y_pred_severity_survivors + 1\n",
    "\n",
    "final_pred = np.full(len(X_test), 3)\n",
    "final_pred[survivor_mask_test] = y_pred_severity[survivor_mask_test]\n",
    "final_pred = np.nan_to_num(final_pred, nan=3).astype(int)\n",
    "\n",
    "\n",
    "y_true_final = y_true.loc[X_test.index]\n",
    "evaluate_predictions(y_true_final, pd.Series(final_pred, index=X_test.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75bc891d55f1109",
   "metadata": {},
   "source": [
    "### `Štvrtá vlna pandémie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f55dbe78c9ce2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T14:09:17.042495Z",
     "start_time": "2025-05-07T13:59:42.123749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'entropy', 'classifier__max_depth': 20, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 150}\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'entropy', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "\n",
      "=== Hierarchical Metrics ===\n",
      "H-Precision: 0.7670\n",
      "H-Recall:    0.7907\n",
      "H-F1:        0.7787\n"
     ]
    }
   ],
   "source": [
    "X, y_mortality, y_severity, y_true = preprocess_data('../data/4vlna.xlsx')\n",
    "feature_names = X.columns\n",
    "\n",
    "X_train, X_test, y_train_mort, y_test_mort = train_test_split(\n",
    "    X, y_mortality, test_size=0.3, random_state=42, stratify=y_mortality\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), ['Vek']),\n",
    "    ('passthrough', 'passthrough', X.columns.difference(['Vek']))\n",
    "])\n",
    "\n",
    "mort_pipeline = train_random_forest(X_train, y_train_mort, preprocessor)\n",
    "\n",
    "oof_predictions = cross_val_predict(\n",
    "    mort_pipeline, X_train, y_train_mort, cv=5, method='predict'\n",
    ")\n",
    "survivor_mask_train_pred_oof = (oof_predictions == 0)\n",
    "\n",
    "\n",
    "y_train_severity_not_na_mask = y_severity.loc[X_train.index].notna()\n",
    "relevant_mask_train = survivor_mask_train_pred_oof & y_train_severity_not_na_mask\n",
    "X_train_severity = X_train[relevant_mask_train]\n",
    "y_train_severity = y_severity.loc[X_train.index][relevant_mask_train]\n",
    "\n",
    "\n",
    "severity_pipeline = train_random_forest(X_train_severity, y_train_severity, preprocessor)\n",
    "\n",
    "y_pred_mortality_test = mort_pipeline.predict(X_test)\n",
    "survivor_mask_test = (y_pred_mortality_test == 0)\n",
    "\n",
    "X_test_severity = X_test[survivor_mask_test]\n",
    "y_pred_severity = np.full(len(X_test), np.nan)\n",
    "\n",
    "if not X_test_severity.empty:\n",
    "    y_pred_severity_survivors = severity_pipeline.predict(X_test_severity)\n",
    "    y_pred_severity[survivor_mask_test] = y_pred_severity_survivors + 1\n",
    "\n",
    "final_pred = np.full(len(X_test), 3)\n",
    "final_pred[survivor_mask_test] = y_pred_severity[survivor_mask_test]\n",
    "final_pred = np.nan_to_num(final_pred, nan=3).astype(int)\n",
    "\n",
    "\n",
    "y_true_final = y_true.loc[X_test.index]\n",
    "evaluate_predictions(y_true_final, pd.Series(final_pred, index=X_test.index))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
